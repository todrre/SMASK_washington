{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d578e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.neighbors as skl_nb\n",
    "import sklearn.model_selection as skl_ms\n",
    "\n",
    "data = pd.read_csv('training_data_VT2026.csv', dtype={'ID': str}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22464467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom features\n",
    "\n",
    "data[\"increase_stock\"] = data[\"increase_stock\"].map({\n",
    "    \"low_bike_demand\": 0,\n",
    "    \"high_bike_demand\": 1\n",
    "})\n",
    "\n",
    "data[\"day\"] = ((data['hour_of_day'] >= 6) & (data['hour_of_day'] <= 21)).astype(int)\n",
    "\n",
    "data[\"snow\"] = (data['snowdepth'] > 0).astype(int)\n",
    "\n",
    "data[\"good_weather\"] = ( \n",
    "        (data[\"humidity\"] <= 60).astype(int) + \n",
    "        (data[\"precip\"] == 0).astype(int) + \n",
    "        (data[\"windspeed\"] <= 20).astype(int) + \n",
    "        (data[\"cloudcover\"] <= 50).astype(int) + \n",
    "        (data[\"visibility\"] >= 10).astype(int) + \n",
    "        data[\"snow\"]\n",
    "    )\n",
    "\n",
    "data[\"dry_warm_index\"] = (\n",
    "        data['temp'] * (100-data[\"humidity\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c4a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and testing data\n",
    "\n",
    "N = len(data)\n",
    "\n",
    "M = N//2\n",
    "\n",
    "\n",
    "# Generate random indices for the test set without replacement\n",
    "test_indices = np.random.choice(N, size=M, replace=False)\n",
    "\n",
    "# Get the actual index labels of the DataFrame\n",
    "all_indices = data.index\n",
    "\n",
    "# Create a boolean mask for the test indices. Returns a boolean array of the\n",
    "# same shape as all_auto_indices that is True where an element of\n",
    "# all_indices is in all_indices[test_indices] and False otherwise.\n",
    "test_mask = np.isin(all_indices, all_indices[test_indices])\n",
    "\n",
    "# Select the train and test dataframes using the boolean mask\n",
    "test = data[test_mask]\n",
    "train = data[~test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62dbe6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rush hour at day 0: 15.384615384615385\n",
      "Rush hour at day 1: 15.846153846153847\n",
      "Rush hour at day 2: 15.31578947368421\n",
      "Rush hour at day 3: 15.11111111111111\n",
      "Rush hour at day 4: 14.7\n",
      "Rush hour at day 5: 14.18918918918919\n",
      "Rush hour at day 6: 14.647058823529411\n"
     ]
    }
   ],
   "source": [
    "# Calculate rush hour and rush hour Gaussian\n",
    "\n",
    "\n",
    "# Viktigt! mean_time och std_time definierade utifrån träningsdatan\n",
    "mean_time = train.loc[data[\"increase_stock\"] == 1, \"hour_of_day\"].mean()\n",
    "std_time  = train.loc[data[\"increase_stock\"] == 1, \"hour_of_day\"].std()\n",
    "\n",
    "train[\"rush_hour\"] = ((train[\"hour_of_day\"] >= (mean_time-(1.45*std_time))) & (train[\"hour_of_day\"] <= (mean_time+(1.45*std_time)))).astype(int)\n",
    "train['rush_hour_gaussian'] = np.exp(-(train['hour_of_day'] - mean_time)**2 / (2*std_time**2))\n",
    "\n",
    "test[\"rush_hour\"] = ((test[\"hour_of_day\"] >= (mean_time-(1.45*std_time))) & (data[\"hour_of_day\"] <= (mean_time+(1.45*std_time)))).astype(int)\n",
    "test['rush_hour_gaussian'] = np.exp(-(test['hour_of_day'] - mean_time)**2 / (2*std_time**2))\n",
    "\n",
    "\n",
    "# Rush hour Gaussian implementerar rush_hour som numerisk egenskap istället för kategorisk. Blir en mer flytande skala, gav bättre resultat iaf med log-reg.\n",
    "# Ett alternativt sätt att definiera rush_hour är att definiera den separat för varje dag i veckan. Ger i princip en mer träffsäker modell men riskera roverfitting om för lite data finns tillgänglig för en dag\n",
    "# Vi får välja vilken vi använder gemensamt genom att typ testa vilken som funkar bäst för alla. Ska bli spännande.\n",
    "for d in range(7):\n",
    "    mask = data[\"day_of_week\"] == d\n",
    "    mean_time_this_day = train.loc[(train[\"increase_stock\"] == 1) & (train['day_of_week'] == d), \"hour_of_day\"].mean()\n",
    "    std_time_this_day = train.loc[(train[\"increase_stock\"] == 1) & (train['day_of_week'] == d), \"hour_of_day\"].std()\n",
    "    print(f\"Rush hour at day {d}: {mean_time_this_day}\")\n",
    "\n",
    "    train.loc[(mask & (train[\"hour_of_day\"] >= (mean_time_this_day-(1.5*std_time_this_day))) & (train[\"hour_of_day\"] <= (mean_time_this_day+(1.5*std_time_this_day)))), 'rush_hour'] = 1\n",
    "    train.loc[(mask & (train[\"hour_of_day\"] < (mean_time_this_day-(1.5*std_time_this_day))) | (train[\"hour_of_day\"] > (mean_time_this_day+(1.5*std_time_this_day)))), 'rush_hour'] = 0\n",
    "    train.loc[(mask), 'rush_hour_gaussian'] = np.exp(-(train['hour_of_day'] - mean_time_this_day)**2 / (2*std_time_this_day**2))\n",
    "\n",
    "    test.loc[(mask & (test[\"hour_of_day\"] >= (mean_time_this_day-(1.5*std_time_this_day))) & (test[\"hour_of_day\"] <= (mean_time_this_day+(1.5*std_time_this_day)))), 'rush_hour'] = 1\n",
    "    test.loc[(mask & (test[\"hour_of_day\"] < (mean_time_this_day-(1.5*std_time_this_day))) | (test[\"hour_of_day\"] > (mean_time_this_day+(1.5*std_time_this_day)))), 'rush_hour'] = 0\n",
    "    test.loc[(mask), 'rush_hour_gaussian'] = np.exp(-(test['hour_of_day'] - mean_time_this_day)**2 / (2*std_time_this_day**2))\n",
    "\n",
    "#data['rush_hour_og'] = ((data[\"hour_of_day\"] >= (mean_time-(1.45*std_time))) & (data[\"hour_of_day\"] <= (mean_time+(1.45*std_time)))).astype(int)\n",
    "#data['rush_hour_gaussian_og'] = np.exp(-(data['hour_of_day'] - mean_time)**2 / (2*std_time**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85b61a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dry_warm_index', 'rush_hour_gaussian', 'temp', 'humidity', 'good_weather', 'windspeed', 'visibility', 'precip', 'snowdepth', 'cloudcover']\n",
      "['day', 'rush_hour', 'hour_of_day', 'summertime', 'weekday', 'day_of_week', 'holiday', 'month']\n"
     ]
    }
   ],
   "source": [
    "# Choose which features to use\n",
    "\n",
    "numerical_features = ['temp', 'humidity', 'precip', 'snowdepth', 'windspeed',\n",
    "                      'cloudcover', 'visibility', 'good_weather', 'dry_warm_index', 'rush_hour_gaussian']\n",
    "cat_features = ['hour_of_day', 'day_of_week', 'month', 'holiday',\n",
    "                'weekday', 'summertime', 'day', 'rush_hour']\n",
    "\n",
    "corr_numerical = (\n",
    "    train[numerical_features + [\"increase_stock\"]]\n",
    "    .corr()\n",
    "    [\"increase_stock\"]\n",
    "    .drop(\"increase_stock\")\n",
    "    .sort_values(key=abs, ascending=False)\n",
    ")\n",
    "\n",
    "corr_cat = (\n",
    "    train[cat_features + [\"increase_stock\"]]\n",
    "    .corr()\n",
    "    [\"increase_stock\"]\n",
    "    .drop(\"increase_stock\")\n",
    "    .sort_values(key=abs, ascending=False)\n",
    ")\n",
    "numerical_features = [str(corr_numerical.index[i]) for i in range(len(numerical_features))]\n",
    "cat_features = [str(corr_cat.index[i]) for i in range(len(cat_features))]\n",
    "\n",
    "print(numerical_features)\n",
    "print(cat_features)\n",
    "\n",
    "best_numerical_features = ['dry_warm_index', 'rush_hour_gaussian'] # k=2\n",
    "best_cat_features = ['day', 'hour_of_day', 'summertime', 'weekday', 'day_of_week', 'month'] # k=6\n",
    "\n",
    "X_train = train[best_numerical_features + best_cat_features]\n",
    "y_train = train['increase_stock']\n",
    "\n",
    "X_test = test[best_numerical_features + best_cat_features]\n",
    "y_test = test['increase_stock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e87dfa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_numerical_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m\n\u001b[0;32m     14\u001b[0m num_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     15\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#('select', SelectKBest(score_func=f_classif))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m ])\n\u001b[0;32m     20\u001b[0m cat_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     21\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     22\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#('select', SelectKBest(score_func=f_classif))\u001b[39;00m\n\u001b[0;32m     24\u001b[0m ])\n\u001b[0;32m     26\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[0;32m     27\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 28\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, num_pipeline, \u001b[43mbest_numerical_features\u001b[49m),\n\u001b[0;32m     29\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, cat_pipeline, best_cat_features)\n\u001b[0;32m     30\u001b[0m     ]\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m model_lr \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     34\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     35\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)) \u001b[38;5;66;03m# l1 om accuracy, l2 om ROC-AUC\u001b[39;00m\n\u001b[0;32m     36\u001b[0m ])\n\u001b[0;32m     38\u001b[0m model_lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_numerical_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Log-reg\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    #('select', SelectKBest(score_func=f_classif))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    #('select', SelectKBest(score_func=f_classif))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, best_numerical_features),\n",
    "        ('cat', cat_pipeline, best_cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_lr = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', LogisticRegression(penalty = 'l1', C=1.0, solver = 'liblinear', max_iter=1000)) # l1 om accuracy, l2 om ROC-AUC\n",
    "])\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "preds = model_lr.predict(X_test)\n",
    "score = model_lr.score(X_test, y_test)\n",
    "error = np.mean(preds != y_test)\n",
    "\n",
    "print(\"Test accuracy:\", score)\n",
    "print(\"Test error:\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA & QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2572c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
